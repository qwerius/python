import{_ as s,c as i,ag as n,o as t}from"./chunks/framework.DNBSSkcL.js";const o=JSON.parse('{"title":"Dask Library","description":"","frontmatter":{},"headers":[],"relativePath":"dasar_python/dask.md","filePath":"dasar_python/dask.md"}'),e={name:"dasar_python/dask.md"};function l(k,a,h,p,r,d){return t(),i("div",null,a[0]||(a[0]=[n(`<h1 id="dask-library" tabindex="-1"><strong>Dask Library</strong> <a class="header-anchor" href="#dask-library" aria-label="Permalink to &quot;**Dask Library**&quot;">​</a></h1><p>Dask adalah pustaka open-source di Python yang dirancang untuk menangani komputasi paralel dan pengolahan data skala besar. Dask memiliki API yang mirip dengan Pandas, NumPy, dan Scikit-Learn, sehingga mudah digunakan oleh pengguna yang sudah terbiasa dengan pustaka tersebut.</p><p>Dask memungkinkan pengguna untuk bekerja dengan dataset yang lebih besar dari kapasitas RAM dengan cara membagi data menjadi partisi kecil dan mengeksekusinya secara paralel di CPU atau dalam cluster komputasi.</p><h2 id="perbedaan-dask-vs-pandas" tabindex="-1"><strong>Perbedaan Dask vs Pandas</strong> <a class="header-anchor" href="#perbedaan-dask-vs-pandas" aria-label="Permalink to &quot;**Perbedaan Dask vs Pandas**&quot;">​</a></h2><table tabindex="0"><thead><tr><th><strong>Fitur</strong></th><th><strong>Dask</strong></th><th><strong>Pandas</strong></th></tr></thead><tbody><tr><td><strong>Ukuran Data</strong></td><td>Bisa menangani dataset lebih besar dari RAM</td><td>Hanya bisa menangani data dalam RAM</td></tr><tr><td><strong>Eksekusi</strong></td><td>Lazy Evaluation (tidak langsung dieksekusi)</td><td>Eager Execution (langsung dijalankan)</td></tr><tr><td><strong>Paralelisasi</strong></td><td>Mendukung multi-core processing &amp; cluster</td><td>Hanya berjalan di single-core</td></tr><tr><td><strong>Kompatibilitas</strong></td><td>Bisa digunakan dengan Pandas, NumPy, Scikit-Learn</td><td>Hanya mendukung Pandas</td></tr><tr><td><strong>Kecepatan</strong></td><td>Lebih cepat untuk big data</td><td>Lebih cepat untuk small data</td></tr><tr><td><strong>Skalabilitas</strong></td><td>Bisa dijalankan di laptop hingga cluster besar</td><td>Terbatas pada satu mesin</td></tr></tbody></table><blockquote><ul><li>Gunakan Pandas jika dataset cukup kecil untuk muat di memori.</li><li>Gunakan Dask jika dataset terlalu besar untuk RAM atau membutuhkan pemrosesan paralel.</li></ul></blockquote><h2 id="kelebihan-dan-kekurangan-dask" tabindex="-1"><strong>Kelebihan dan Kekurangan Dask</strong> <a class="header-anchor" href="#kelebihan-dan-kekurangan-dask" aria-label="Permalink to &quot;**Kelebihan dan Kekurangan Dask**&quot;">​</a></h2><h3 id="kelebihan-dask" tabindex="-1"><strong>Kelebihan Dask</strong> <a class="header-anchor" href="#kelebihan-dask" aria-label="Permalink to &quot;**Kelebihan Dask**&quot;">​</a></h3><ul><li>Bisa menangani dataset besar yang tidak bisa ditampung di RAM.</li><li>Paralelisasi otomatis, memanfaatkan banyak core CPU.</li><li>API mirip Pandas, sehingga mudah dipelajari dan digunakan.</li><li>Mendukung lazy evaluation, sehingga lebih efisien dalam penggunaan memori.</li><li>Dapat berjalan di cluster, seperti di Kubernetes, AWS, atau Google Cloud.</li></ul><h3 id="kekurangan-dask" tabindex="-1"><strong>Kekurangan Dask</strong> <a class="header-anchor" href="#kekurangan-dask" aria-label="Permalink to &quot;**Kekurangan Dask**&quot;">​</a></h3><ul><li>Lebih kompleks dibanding Pandas karena perlu memahami partisi data dan scheduler.</li><li>Lebih lambat untuk dataset kecil, karena overhead dari paralelisasi.</li><li>Tidak semua fitur Pandas didukung, meskipun sebagian besar telah diimplementasikan.</li><li>Lazy execution bisa membingungkan bagi pengguna baru, karena operasi tidak langsung dieksekusi.</li></ul><h2 id="kasus-penggunaan-dask" tabindex="-1"><strong>Kasus Penggunaan Dask</strong> <a class="header-anchor" href="#kasus-penggunaan-dask" aria-label="Permalink to &quot;**Kasus Penggunaan Dask**&quot;">​</a></h2><p>Dask sangat berguna dalam berbagai skenario, terutama untuk data dalam jumlah besar atau yang membutuhkan pemrosesan intensif.</p><h3 id="_1-analisis-dataset-besar" tabindex="-1"><strong>1. Analisis Dataset Besar</strong> <a class="header-anchor" href="#_1-analisis-dataset-besar" aria-label="Permalink to &quot;**1. Analisis Dataset Besar**&quot;">​</a></h3><ul><li>Mengolah data jutaan atau miliaran baris tanpa memenuhi RAM.</li><li>Contoh: Analisis log server atau data sensor IoT yang sangat besar.</li></ul><h3 id="_2-machine-learning-dengan-big-data" tabindex="-1"><strong>2. Machine Learning dengan Big Data</strong> <a class="header-anchor" href="#_2-machine-learning-dengan-big-data" aria-label="Permalink to &quot;**2. Machine Learning dengan Big Data**&quot;">​</a></h3><ul><li>Melatih model machine learning dengan dataset besar yang tidak bisa ditangani Pandas.</li><li>Integrasi dengan <code>dask-ml</code> untuk training paralel.</li></ul><h3 id="_3-data-engineering-etl-extract-transform-load" tabindex="-1"><strong>3. Data Engineering &amp; ETL (Extract, Transform, Load)</strong> <a class="header-anchor" href="#_3-data-engineering-etl-extract-transform-load" aria-label="Permalink to &quot;**3. Data Engineering &amp; ETL (Extract, Transform, Load)**&quot;">​</a></h3><ul><li>Membersihkan dan mengubah data sebelum dimasukkan ke database.</li><li>Contoh: Proses data keuangan atau data transaksi dalam skala besar.</li></ul><h3 id="_4-cloud-computing-distributed-computing" tabindex="-1"><strong>4. Cloud Computing &amp; Distributed Computing</strong> <a class="header-anchor" href="#_4-cloud-computing-distributed-computing" aria-label="Permalink to &quot;**4. Cloud Computing &amp; Distributed Computing**&quot;">​</a></h3><ul><li>Memanfaatkan cluster untuk menjalankan analisis data di AWS, Google Cloud, atau Kubernetes.</li><li>Contoh: Pemrosesan data real-time dari berbagai sumber (misalnya data streaming).</li></ul><hr><blockquote><p>Dask adalah solusi yang tepat untuk menangani dataset besar yang tidak dapat dimuat sepenuhnya di RAM. Dengan dukungan terhadap komputasi paralel dan integrasi dengan berbagai pustaka Python, Dask menjadi pilihan yang baik untuk analisis data skala besar, pemrosesan ETL, serta machine learning berbasis big data. Namun, pengguna perlu memahami konsep partisi data dan eksekusi paralel agar dapat memanfaatkan Dask secara optimal.</p></blockquote><h2 id="struktur-dasar-dask" tabindex="-1"><strong>Struktur Dasar Dask</strong> <a class="header-anchor" href="#struktur-dasar-dask" aria-label="Permalink to &quot;**Struktur Dasar Dask**&quot;">​</a></h2><p>Dask menyediakan beberapa struktur data utama yang dirancang untuk menangani berbagai jenis data dan operasi secara paralel. Struktur ini mencerminkan pustaka yang sudah dikenal dalam ekosistem Python, seperti Pandas dan NumPy, tetapi dengan kemampuan menangani data besar dan pemrosesan terdistribusi.</p><h3 id="_1-dask-dataframe-vs-pandas-dataframe" tabindex="-1"><strong>1. Dask DataFrame vs Pandas DataFrame</strong> <a class="header-anchor" href="#_1-dask-dataframe-vs-pandas-dataframe" aria-label="Permalink to &quot;**1. Dask DataFrame vs Pandas DataFrame**&quot;">​</a></h3><p>Dask DataFrame adalah versi terdistribusi dari Pandas DataFrame yang dirancang untuk menangani dataset lebih besar dari kapasitas RAM dengan cara membagi data menjadi beberapa partisi yang diproses secara paralel.</p><h4 id="perbedaan-utama" tabindex="-1"><strong>Perbedaan Utama</strong> <a class="header-anchor" href="#perbedaan-utama" aria-label="Permalink to &quot;**Perbedaan Utama**&quot;">​</a></h4><table tabindex="0"><thead><tr><th><strong>Fitur</strong></th><th><strong>Dask DataFrame</strong></th><th><strong>Pandas DataFrame</strong></th></tr></thead><tbody><tr><td><strong>Ukuran Data</strong></td><td>Bisa lebih besar dari RAM</td><td>Harus muat dalam RAM</td></tr><tr><td><strong>Eksekusi</strong></td><td>Lazy evaluation (ditunda hingga diperlukan)</td><td>Eager evaluation (langsung dieksekusi)</td></tr><tr><td><strong>Paralelisasi</strong></td><td>Mendukung multi-core &amp; cluster</td><td>Hanya berjalan pada satu core</td></tr><tr><td><strong>Fitur yang Didukung</strong></td><td>Sebagian besar API Pandas didukung</td><td>Semua fitur Pandas tersedia</td></tr><tr><td><strong>Kecepatan</strong></td><td>Lebih cepat untuk dataset besar</td><td>Lebih cepat untuk dataset kecil</td></tr></tbody></table><h4 id="kapan-menggunakan-dask-dataframe" tabindex="-1"><strong>Kapan Menggunakan Dask DataFrame?</strong> <a class="header-anchor" href="#kapan-menggunakan-dask-dataframe" aria-label="Permalink to &quot;**Kapan Menggunakan Dask DataFrame?**&quot;">​</a></h4><ul><li>Ketika dataset terlalu besar untuk dimuat dalam RAM.</li><li>Saat membutuhkan pemrosesan paralel untuk meningkatkan performa.</li><li>Untuk pipeline data yang berjalan di cluster atau dalam cloud computing.</li></ul><h4 id="contoh-penggunaan" tabindex="-1"><strong>Contoh Penggunaan</strong> <a class="header-anchor" href="#contoh-penggunaan" aria-label="Permalink to &quot;**Contoh Penggunaan**&quot;">​</a></h4><p>Menggunakan Dask DataFrame untuk membaca file CSV besar:</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dask.dataframe </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dd</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dd.read_csv(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;data_besar.csv&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(df.head())  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Data diambil hanya dari sebagian partisi</span></span></code></pre></div><h3 id="_2-dask-array-vs-numpy" tabindex="-1"><strong>2. Dask Array vs NumPy</strong> <a class="header-anchor" href="#_2-dask-array-vs-numpy" aria-label="Permalink to &quot;**2. Dask Array vs NumPy**&quot;">​</a></h3><p>Dask Array adalah versi terdistribusi dari NumPy yang memungkinkan manipulasi array besar yang tidak bisa dimuat dalam RAM.</p><h4 id="perbedaan-utama-1" tabindex="-1"><strong>Perbedaan Utama</strong> <a class="header-anchor" href="#perbedaan-utama-1" aria-label="Permalink to &quot;**Perbedaan Utama**&quot;">​</a></h4><table tabindex="0"><thead><tr><th><strong>Fitur</strong></th><th><strong>Dask Array</strong></th><th><strong>NumPy</strong></th></tr></thead><tbody><tr><td><strong>Ukuran Data</strong></td><td>Bisa lebih besar dari RAM</td><td>Harus muat dalam RAM</td></tr><tr><td><strong>Eksekusi</strong></td><td>Lazy evaluation</td><td>Eager evaluation</td></tr><tr><td><strong>Paralelisasi</strong></td><td>Mendukung multi-core &amp; cluster</td><td>Hanya berjalan di satu core</td></tr><tr><td><strong>Kompatibilitas</strong></td><td>API mirip dengan NumPy</td><td>API NumPy penuh</td></tr><tr><td><strong>Kecepatan</strong></td><td>Lebih cepat untuk dataset besar</td><td>Lebih cepat untuk dataset kecil</td></tr></tbody></table><h4 id="kapan-menggunakan-dask-array" tabindex="-1"><strong>Kapan Menggunakan Dask Array?</strong> <a class="header-anchor" href="#kapan-menggunakan-dask-array" aria-label="Permalink to &quot;**Kapan Menggunakan Dask Array?**&quot;">​</a></h4><ul><li>Saat bekerja dengan array besar yang tidak bisa ditampung dalam RAM.</li><li>Ketika membutuhkan operasi paralel pada array besar.</li><li>Untuk analisis numerik atau machine learning skala besar.</li></ul><h4 id="contoh-penggunaan-1" tabindex="-1"><strong>Contoh Penggunaan</strong> <a class="header-anchor" href="#contoh-penggunaan-1" aria-label="Permalink to &quot;**Contoh Penggunaan**&quot;">​</a></h4><p>Menggunakan Dask Array untuk membuat array besar:</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dask.array </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> da</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> da.random.random((</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10000</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10000</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">chunks</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1000</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1000</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Array besar dengan partisi</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(x.mean().compute())  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Harus menggunakan .compute() untuk eksekusi</span></span></code></pre></div><h3 id="_3-dask-bag-untuk-data-semi-terstruktur" tabindex="-1"><strong>3. Dask Bag untuk Data Semi-Terstruktur</strong> <a class="header-anchor" href="#_3-dask-bag-untuk-data-semi-terstruktur" aria-label="Permalink to &quot;**3. Dask Bag untuk Data Semi-Terstruktur**&quot;">​</a></h3><p>Dask Bag dirancang untuk menangani data semi-terstruktur seperti JSON, log, atau data teks yang tidak memiliki format tabel atau array tetap.</p><h3 id="kapan-menggunakan-dask-bag" tabindex="-1"><strong>Kapan Menggunakan Dask Bag?</strong> <a class="header-anchor" href="#kapan-menggunakan-dask-bag" aria-label="Permalink to &quot;**Kapan Menggunakan Dask Bag?**&quot;">​</a></h3><ul><li>Saat bekerja dengan data yang tidak berbentuk tabel seperti JSON, XML, atau log server.</li><li>Untuk analisis data berbasis teks dalam jumlah besar.</li><li>Ketika membutuhkan pemrosesan batch untuk file teks besar.</li></ul><h4 id="contoh-penggunaan-2" tabindex="-1"><strong>Contoh Penggunaan</strong> <a class="header-anchor" href="#contoh-penggunaan-2" aria-label="Permalink to &quot;**Contoh Penggunaan**&quot;">​</a></h4><p>Misalnya, membaca file JSON besar dengan Dask Bag:</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dask.bag </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> db</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">bag </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> db.read_text(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;data_log.json&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">).map(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">lambda</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x: x.upper())  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Mengubah teks menjadi huruf besar</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(bag.take(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Mengambil 5 baris pertama</span></span></code></pre></div><hr><blockquote><ul><li><strong>Gunakan Dask DataFrame</strong> jika bekerja dengan data terstruktur seperti tabel dalam CSV atau database.</li><li><strong>Gunakan Dask Array</strong> jika menangani data numerik besar yang biasanya dikerjakan dengan NumPy.</li><li><strong>Gunakan Dask Bag</strong> jika memproses data semi-terstruktur seperti JSON atau log.</li></ul></blockquote><p>Dask memungkinkan skalabilitas tinggi untuk berbagai jenis data dengan API yang familiar, membuatnya cocok untuk analisis data skala besar tanpa membebani memori komputer.</p><h2 id="membaca-dan-menyimpan-data-dengan-dask" tabindex="-1"><strong>Membaca dan Menyimpan Data dengan Dask</strong> <a class="header-anchor" href="#membaca-dan-menyimpan-data-dengan-dask" aria-label="Permalink to &quot;**Membaca dan Menyimpan Data dengan Dask**&quot;">​</a></h2><p>Dask menyediakan berbagai metode untuk membaca dan menyimpan data dalam berbagai format. Struktur ini mirip dengan Pandas, tetapi mendukung pemrosesan paralel dan dataset besar yang tidak muat dalam RAM.</p><hr><h3 id="_1-membaca-data" tabindex="-1"><strong>1. Membaca Data</strong> <a class="header-anchor" href="#_1-membaca-data" aria-label="Permalink to &quot;**1. Membaca Data**&quot;">​</a></h3><p>Dask mendukung beberapa format umum untuk membaca data.</p><h4 id="membaca-csv" tabindex="-1"><strong>Membaca CSV</strong> <a class="header-anchor" href="#membaca-csv" aria-label="Permalink to &quot;**Membaca CSV**&quot;">​</a></h4><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dask.dataframe </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dd</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dd.read_csv(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;data.csv&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(df.head())  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Hanya menampilkan sebagian data</span></span></code></pre></div><p><strong>Kelebihan:</strong></p><ul><li>Bisa membaca file besar secara bertahap dengan <code>blocksize</code> atau <code>chunksize</code>.</li><li>Bisa membaca banyak file sekaligus dengan wildcard (<code>*.csv</code>).</li></ul><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dd.read_csv(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;data_folder/*.csv&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><hr><h4 id="membaca-parquet" tabindex="-1"><strong>Membaca Parquet</strong> <a class="header-anchor" href="#membaca-parquet" aria-label="Permalink to &quot;**Membaca Parquet**&quot;">​</a></h4><p>Parquet adalah format biner yang lebih efisien dibandingkan CSV karena mendukung kompresi dan penyimpanan kolom.</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dd.read_parquet(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;data.parquet&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p><strong>Keuntungan menggunakan Parquet:</strong></p><ul><li>Lebih cepat dibandingkan CSV.</li><li>Lebih hemat ruang penyimpanan.</li><li>Bisa membaca hanya kolom yang diperlukan untuk efisiensi.</li></ul><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dd.read_parquet(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;data.parquet&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">columns</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;nama&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;umur&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span></code></pre></div><hr><h4 id="membaca-json" tabindex="-1"><strong>Membaca JSON</strong> <a class="header-anchor" href="#membaca-json" aria-label="Permalink to &quot;**Membaca JSON**&quot;">​</a></h4><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dd.read_json(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;data.json&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">lines</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>JSON sering digunakan untuk data semi-terstruktur. Parameter <code>lines=True</code> digunakan untuk membaca JSON dengan format satu objek per baris.</p><hr><h3 id="_2-menyimpan-data" tabindex="-1"><strong>2. Menyimpan Data</strong> <a class="header-anchor" href="#_2-menyimpan-data" aria-label="Permalink to &quot;**2. Menyimpan Data**&quot;">​</a></h3><p>Dask mendukung penyimpanan ke berbagai format file.</p><h4 id="menyimpan-ke-csv" tabindex="-1"><strong>Menyimpan ke CSV</strong> <a class="header-anchor" href="#menyimpan-ke-csv" aria-label="Permalink to &quot;**Menyimpan ke CSV**&quot;">​</a></h4><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df.to_csv(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;output_folder&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">index</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">False</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>Dask akan membagi file menjadi beberapa bagian (<code>output_folder/part-*.csv</code>). Jika ingin menyimpan dalam satu file, perlu menggunakan <code>compute()</code>:</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df.compute().to_csv(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;output.csv&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">index</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">False</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><hr><h4 id="menyimpan-ke-parquet" tabindex="-1"><strong>Menyimpan ke Parquet</strong> <a class="header-anchor" href="#menyimpan-ke-parquet" aria-label="Permalink to &quot;**Menyimpan ke Parquet**&quot;">​</a></h4><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df.to_parquet(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;output_folder&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>Parquet lebih disarankan untuk data besar karena lebih cepat dibaca dan lebih hemat ruang.</p><h2 id="operasi-dasar-pada-dask-dataframe" tabindex="-1"><strong>Operasi Dasar pada Dask DataFrame</strong> <a class="header-anchor" href="#operasi-dasar-pada-dask-dataframe" aria-label="Permalink to &quot;**Operasi Dasar pada Dask DataFrame**&quot;">​</a></h2><p>Dask DataFrame mendukung operasi yang mirip dengan Pandas, tetapi dengan eksekusi paralel dan pemrosesan berbasis partisi.</p><hr><h3 id="_1-filtering-data" tabindex="-1"><strong>1. Filtering Data</strong> <a class="header-anchor" href="#_1-filtering-data" aria-label="Permalink to &quot;**1. Filtering Data**&quot;">​</a></h3><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df_filtered </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> df[df[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;nilai&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(df_filtered.head())</span></span></code></pre></div><p>Filtering dilakukan secara paralel pada setiap partisi, meningkatkan efisiensi dibandingkan Pandas.</p><hr><h3 id="_2-grouping-data" tabindex="-1"><strong>2. Grouping Data</strong> <a class="header-anchor" href="#_2-grouping-data" aria-label="Permalink to &quot;**2. Grouping Data**&quot;">​</a></h3><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df_grouped </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> df.groupby(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;kategori&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">).mean()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(df_grouped.compute())  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Perlu compute() untuk melihat hasilnya</span></span></code></pre></div><p>Dask mengelompokkan data dalam partisi masing-masing sebelum menggabungkan hasilnya.</p><hr><h3 id="_3-joins-dan-merges" tabindex="-1"><strong>3. Joins dan Merges</strong> <a class="header-anchor" href="#_3-joins-dan-merges" aria-label="Permalink to &quot;**3. Joins dan Merges**&quot;">​</a></h3><p>Menggabungkan dua DataFrame berdasarkan kolom yang sama:</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df1 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dd.read_csv(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;data1.csv&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df2 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dd.read_csv(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;data2.csv&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df_merged </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dd.merge(df1, df2, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">on</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;id&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(df_merged.head())</span></span></code></pre></div><p>Dask melakukan join dengan cara membagi data dalam beberapa partisi, sehingga lebih efisien untuk dataset besar.</p><h2 id="perbedaan-compute-vs-lazy-evaluation" tabindex="-1"><strong>Perbedaan <code>.compute()</code> vs Lazy Evaluation</strong> <a class="header-anchor" href="#perbedaan-compute-vs-lazy-evaluation" aria-label="Permalink to &quot;**Perbedaan \`.compute()\` vs Lazy Evaluation**&quot;">​</a></h2><p>Dask menggunakan <strong>lazy evaluation</strong>, yaitu menunda eksekusi operasi sampai benar-benar diperlukan.</p><hr><h3 id="_1-mengapa-dask-tidak-langsung-mengeksekusi-perintah" tabindex="-1"><strong>1. Mengapa Dask Tidak Langsung Mengeksekusi Perintah?</strong> <a class="header-anchor" href="#_1-mengapa-dask-tidak-langsung-mengeksekusi-perintah" aria-label="Permalink to &quot;**1. Mengapa Dask Tidak Langsung Mengeksekusi Perintah?**&quot;">​</a></h3><p>Saat menggunakan Pandas, setiap operasi langsung dieksekusi di memori. Namun, dalam Dask, operasi hanya membangun <strong>graf tugas</strong> tanpa langsung menjalankan perhitungan.</p><p>Contoh:</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df_filtered </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> df[df[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;nilai&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Tidak langsung dieksekusi</span></span></code></pre></div><p>Dask hanya membuat rencana eksekusi, tetapi tidak menjalankannya hingga dipanggil <code>.compute()</code>.</p><p>Keuntungannya:</p><ul><li>Lebih hemat memori karena tidak menyimpan hasil antara.</li><li>Bisa mengoptimalkan beberapa operasi sebelum dieksekusi.</li><li>Mendukung eksekusi paralel pada beberapa partisi atau cluster.</li></ul><hr><h3 id="_2-kapan-harus-menggunakan-compute" tabindex="-1"><strong>2. Kapan Harus Menggunakan <code>.compute()</code>?</strong> <a class="header-anchor" href="#_2-kapan-harus-menggunakan-compute" aria-label="Permalink to &quot;**2. Kapan Harus Menggunakan \`.compute()\`?**&quot;">​</a></h3><p>Gunakan <code>.compute()</code> hanya ketika perlu mendapatkan hasil akhir dalam bentuk Pandas DataFrame atau nilai numerik.</p><p>Contoh:</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df_result </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> df.groupby(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;kategori&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">).mean()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(df_result.compute())  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Menjalankan perhitungan dan menampilkan hasil</span></span></code></pre></div><p>Jika tidak menggunakan <code>.compute()</code>, objek yang dihasilkan hanya berupa grafik tugas dan tidak akan menampilkan hasil.</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(df_result)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Hanya menunjukkan informasi graf tugas, bukan hasilnya</span></span></code></pre></div><hr><p><strong>Kesimpulan:</strong></p><ul><li><strong>Gunakan lazy evaluation</strong> untuk efisiensi memori dan optimasi otomatis.</li><li><strong>Gunakan <code>.compute()</code></strong> hanya jika hasilnya benar-benar dibutuhkan untuk analisis lebih lanjut.</li><li>Jika ingin mengonversi Dask DataFrame ke Pandas DataFrame untuk operasi lebih lanjut, gunakan <code>.compute()</code>.</li></ul><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df_pandas </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> df.compute()  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Mengubah Dask DataFrame menjadi Pandas DataFrame</span></span></code></pre></div><h2 id="dask-untuk-machine-learning-big-data" tabindex="-1">Dask untuk Machine Learning &amp; Big Data <a class="header-anchor" href="#dask-untuk-machine-learning-big-data" aria-label="Permalink to &quot;Dask untuk Machine Learning &amp; Big Data&quot;">​</a></h2><p>Dask tidak hanya digunakan untuk pemrosesan data skala besar tetapi juga dapat diterapkan dalam analisis data dan machine learning. Dask memungkinkan pelatihan model pada dataset yang lebih besar daripada yang bisa ditangani dalam memori menggunakan pendekatan paralel dan terdistribusi.</p><hr><h3 id="_1-dask-dengan-scikit-learn" tabindex="-1"><strong>1. Dask dengan Scikit-Learn</strong> <a class="header-anchor" href="#_1-dask-dengan-scikit-learn" aria-label="Permalink to &quot;**1. Dask dengan Scikit-Learn**&quot;">​</a></h3><p>Dask dapat digunakan bersama Scikit-Learn untuk meningkatkan performa pelatihan model, terutama pada dataset besar.</p><h4 id="menggunakan-dask-ml-untuk-model-machine-learning" tabindex="-1"><strong>Menggunakan <code>dask-ml</code> untuk Model Machine Learning</strong> <a class="header-anchor" href="#menggunakan-dask-ml-untuk-model-machine-learning" aria-label="Permalink to &quot;**Menggunakan \`dask-ml\` untuk Model Machine Learning**&quot;">​</a></h4><p><code>dask-ml</code> adalah pustaka yang dirancang untuk mengintegrasikan Dask dengan Scikit-Learn.</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dask_ml.model_selection </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> train_test_split</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dask_ml.linear_model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> LogisticRegression</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dask.array </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> da</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Membuat dataset besar</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">X </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> da.random.random(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">100000</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">50</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">chunks</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1000</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">50</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">y </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> da.random.randint(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">100000</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,), </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">chunks</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1000</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,))</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Split data</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">X_train, X_test, y_train, y_test </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> train_test_split(X, y, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">test_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Melatih model dengan Dask-ML</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> LogisticRegression()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model.fit(X_train, y_train)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Memprediksi</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">y_pred </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> model.predict(X_test)</span></span></code></pre></div><p>Keuntungan menggunakan <code>dask-ml</code>:</p><ul><li><strong>Memanfaatkan komputasi paralel</strong> untuk mempercepat pelatihan.</li><li><strong>Mendukung dataset yang lebih besar dari memori</strong> dengan pendekatan chunking.</li><li><strong>Integrasi dengan Scikit-Learn API</strong> sehingga mudah diadopsi.</li></ul><hr><h4 id="incremental-learning-dengan-dataset-besar" tabindex="-1"><strong>Incremental Learning dengan Dataset Besar</strong> <a class="header-anchor" href="#incremental-learning-dengan-dataset-besar" aria-label="Permalink to &quot;**Incremental Learning dengan Dataset Besar**&quot;">​</a></h4><p><code>Incremental()</code> learning memungkinkan model machine learning untuk belajar dari data secara bertahap, tanpa perlu memuat seluruh dataset ke dalam memori.</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> sklearn.linear_model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> SGDClassifier</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dask_ml.wrappers </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Incremental</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> SGDClassifier()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">inc_model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Incremental(model, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">scoring</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;accuracy&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">inc_model.fit(X_train, y_train, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">classes</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span></code></pre></div><p>Keuntungan dari incremental learning:</p><ul><li>Bisa menangani dataset yang terlalu besar untuk dimuat sekaligus.</li><li>Cocok untuk skenario streaming data atau model yang terus diperbarui.</li></ul><hr><h3 id="_2-integrasi-dask-dengan-big-data-ecosystem" tabindex="-1"><strong>2. Integrasi Dask dengan Big Data Ecosystem</strong> <a class="header-anchor" href="#_2-integrasi-dask-dengan-big-data-ecosystem" aria-label="Permalink to &quot;**2. Integrasi Dask dengan Big Data Ecosystem**&quot;">​</a></h3><p>Dask dapat diintegrasikan dengan berbagai teknologi big data seperti Hadoop, Spark, dan database besar.</p><h4 id="dask-hadoop-spark" tabindex="-1"><strong>Dask + Hadoop / Spark</strong> <a class="header-anchor" href="#dask-hadoop-spark" aria-label="Permalink to &quot;**Dask + Hadoop / Spark**&quot;">​</a></h4><p>Dask dapat membaca dan menulis data langsung ke Hadoop Distributed File System (HDFS).</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dd.read_parquet(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;hdfs:///path/to/data.parquet&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df.to_parquet(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;hdfs:///path/to/output.parquet&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>Jika sudah menggunakan Spark, Dask bisa digunakan sebagai alternatif untuk pemrosesan data yang lebih fleksibel dan sederhana.</p><hr><h4 id="dask-dengan-database-besar-postgresql-mysql-dll" tabindex="-1"><strong>Dask dengan Database Besar (PostgreSQL, MySQL, dll.)</strong> <a class="header-anchor" href="#dask-dengan-database-besar-postgresql-mysql-dll" aria-label="Permalink to &quot;**Dask dengan Database Besar (PostgreSQL, MySQL, dll.)**&quot;">​</a></h4><p>Dask bisa membaca data langsung dari database besar seperti PostgreSQL.</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dask.dataframe </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dd</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> sqlalchemy</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">engine </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> sqlalchemy.create_engine(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;postgresql://user:password@host/dbname&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">query </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;SELECT * FROM table_name&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dd.read_sql_table(query, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">uri</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">engine, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">index_col</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;id&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df.compute()</span></span></code></pre></div><p>Keuntungan menggunakan Dask dengan database:</p><ul><li><strong>Eksekusi kueri paralel</strong> untuk mempercepat pemrosesan.</li><li><strong>Dapat menangani tabel besar</strong> yang tidak muat di memori.</li></ul><hr><h3 id="_3-dask-di-cluster-komputasi" tabindex="-1"><strong>3. Dask di Cluster Komputasi</strong> <a class="header-anchor" href="#_3-dask-di-cluster-komputasi" aria-label="Permalink to &quot;**3. Dask di Cluster Komputasi**&quot;">​</a></h3><p>Ketika dataset dan komputasi menjadi terlalu besar untuk ditangani pada satu mesin, Dask dapat dijalankan dalam cluster untuk meningkatkan skalabilitas.</p><h4 id="menjalankan-dask-di-cluster-dask-distributed" tabindex="-1"><strong>Menjalankan Dask di Cluster (<code>dask.distributed</code>)</strong> <a class="header-anchor" href="#menjalankan-dask-di-cluster-dask-distributed" aria-label="Permalink to &quot;**Menjalankan Dask di Cluster (\`dask.distributed\`)**&quot;">​</a></h4><p>Dask menyediakan <code>dask.distributed</code>, yaitu scheduler yang memungkinkan eksekusi terdistribusi di beberapa node dalam cluster.</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dask.distributed </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Client</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">client </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Client(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">n_workers</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">threads_per_worker</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">memory_limit</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;2GB&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(client)</span></span></code></pre></div><p>Keuntungan menggunakan Dask Cluster:</p><ul><li><strong>Distribusi beban kerja</strong> ke beberapa node atau CPU.</li><li><strong>Optimasi otomatis</strong> berdasarkan ketersediaan sumber daya.</li></ul><hr><h4 id="scaling-up-dengan-dask-kubernetes" tabindex="-1"><strong>Scaling Up dengan Dask Kubernetes</strong> <a class="header-anchor" href="#scaling-up-dengan-dask-kubernetes" aria-label="Permalink to &quot;**Scaling Up dengan Dask Kubernetes**&quot;">​</a></h4><p>Dask dapat berjalan di Kubernetes untuk menyesuaikan kapasitas komputasi berdasarkan beban kerja.</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dask_kubernetes </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> KubeCluster</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">cluster </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> KubeCluster()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">cluster.scale(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Menambah jumlah worker menjadi 10</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">client </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Client(cluster)</span></span></code></pre></div><p>Dengan pendekatan ini, Dask bisa secara otomatis menyesuaikan jumlah worker berdasarkan beban kerja, sehingga lebih efisien dalam penggunaan sumber daya.</p><hr><ul><li><strong>Dask-ML</strong> memungkinkan pelatihan model machine learning dengan dataset besar menggunakan Scikit-Learn API.</li><li><strong>Dask dapat diintegrasikan dengan Hadoop, Spark, dan database besar</strong> untuk pemrosesan data skala besar.</li><li><strong>Dask.distributed memungkinkan eksekusi di cluster</strong>, sedangkan <strong>Dask Kubernetes</strong> bisa digunakan untuk auto-scaling pada cloud computing.</li></ul><h2 id="studi-kasus-penggunaan-dask" tabindex="-1"><strong>Studi Kasus Penggunaan Dask</strong> <a class="header-anchor" href="#studi-kasus-penggunaan-dask" aria-label="Permalink to &quot;**Studi Kasus Penggunaan Dask**&quot;">​</a></h2><p>Dask memungkinkan pemrosesan data skala besar dan paralel yang dapat diterapkan dalam berbagai skenario dunia nyata. Pada tahap ini, fokusnya adalah bagaimana Dask digunakan dalam analisis dataset besar, pemrosesan data real-time, dan membangun pipeline data untuk dashboard analitik.</p><hr><h3 id="studi-kasus" tabindex="-1"><strong>Studi Kasus</strong> <a class="header-anchor" href="#studi-kasus" aria-label="Permalink to &quot;**Studi Kasus**&quot;">​</a></h3><h4 id="_1-analisis-dataset-jutaan-baris" tabindex="-1"><strong>1. Analisis Dataset Jutaan Baris</strong> <a class="header-anchor" href="#_1-analisis-dataset-jutaan-baris" aria-label="Permalink to &quot;**1. Analisis Dataset Jutaan Baris**&quot;">​</a></h4><p>Salah satu keunggulan Dask adalah kemampuannya menangani dataset yang sangat besar yang tidak dapat dimuat sekaligus ke dalam memori.</p><h5 id="contoh-menganalisis-dataset-besar-dengan-dask" tabindex="-1"><strong>Contoh: Menganalisis Dataset Besar dengan Dask</strong> <a class="header-anchor" href="#contoh-menganalisis-dataset-besar-dengan-dask" aria-label="Permalink to &quot;**Contoh: Menganalisis Dataset Besar dengan Dask**&quot;">​</a></h5><p>Misalkan ada dataset transaksi e-commerce berukuran besar dalam format CSV:</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dask.dataframe </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dd</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Membaca dataset besar dengan Dask</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dd.read_csv(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;transaksi_ecommerce.csv&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Melihat struktur data</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(df.dtypes)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Hitung total penjualan per kategori</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">sales_per_category </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> df.groupby(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;kategori&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;total_harga&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].sum()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Eksekusi perhitungan dengan compute()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(sales_per_category.compute())</span></span></code></pre></div><p>Keuntungan menggunakan Dask dalam analisis dataset besar:</p><ul><li><strong>Dapat memproses data lebih cepat</strong> karena menggunakan pemrosesan paralel.</li><li><strong>Tidak memerlukan RAM besar</strong>, karena hanya membaca sebagian data dalam satu waktu.</li><li><strong>Mendukung format data populer</strong> seperti CSV, Parquet, JSON, dan database SQL.</li></ul><hr><h4 id="_2-pemrosesan-data-real-time-dengan-dask" tabindex="-1"><strong>2. Pemrosesan Data Real-Time dengan Dask</strong> <a class="header-anchor" href="#_2-pemrosesan-data-real-time-dengan-dask" aria-label="Permalink to &quot;**2. Pemrosesan Data Real-Time dengan Dask**&quot;">​</a></h4><p>Dask juga dapat digunakan untuk memproses data secara real-time, misalnya untuk memantau transaksi perbankan atau sensor IoT.</p><h5 id="contoh-pemantauan-sensor-iot-secara-real-time" tabindex="-1"><strong>Contoh: Pemantauan Sensor IoT Secara Real-Time</strong> <a class="header-anchor" href="#contoh-pemantauan-sensor-iot-secara-real-time" aria-label="Permalink to &quot;**Contoh: Pemantauan Sensor IoT Secara Real-Time**&quot;">​</a></h5><p>Misalkan ada data dari sensor IoT yang dikirim dalam format JSON:</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dask.bag </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> db</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Membaca data streaming dari JSON</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">data </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> db.read_text(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;data_sensor_*.json&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">).map(json.loads)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Menyaring data dengan suhu di atas 50 derajat</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">filtered_data </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> data.filter(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">lambda</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x: x[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;temperature&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 50</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Menampilkan hasil</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(filtered_data.compute())</span></span></code></pre></div><p>Dask Bag digunakan untuk menangani data semi-terstruktur seperti JSON dan log yang sering dijumpai dalam analisis real-time.</p><p>Keuntungan pemrosesan real-time dengan Dask:</p><ul><li><strong>Bisa menangani data dalam jumlah besar secara efisien.</strong></li><li><strong>Mendukung pemrosesan terdistribusi di cluster.</strong></li><li><strong>Cocok untuk streaming data yang terus diperbarui.</strong></li></ul><hr><h3 id="proyek-akhir" tabindex="-1"><strong>Proyek Akhir</strong> <a class="header-anchor" href="#proyek-akhir" aria-label="Permalink to &quot;**Proyek Akhir**&quot;">​</a></h3><h4 id="_1-membangun-pipeline-data-dengan-dask" tabindex="-1"><strong>1. Membangun Pipeline Data dengan Dask</strong> <a class="header-anchor" href="#_1-membangun-pipeline-data-dengan-dask" aria-label="Permalink to &quot;**1. Membangun Pipeline Data dengan Dask**&quot;">​</a></h4><p>Dalam dunia nyata, banyak proyek data science memerlukan pipeline data yang efisien untuk membersihkan, mengubah, dan menganalisis data.</p><h5 id="contoh-pipeline-data-untuk-analisis-penjualan" tabindex="-1"><strong>Contoh: Pipeline Data untuk Analisis Penjualan</strong> <a class="header-anchor" href="#contoh-pipeline-data-untuk-analisis-penjualan" aria-label="Permalink to &quot;**Contoh: Pipeline Data untuk Analisis Penjualan**&quot;">​</a></h5><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dask.dataframe </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dd</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Membaca data transaksi dari berbagai file CSV</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dd.read_csv(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;data_penjualan_*.csv&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Data Cleaning: Menghapus nilai kosong</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df_clean </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> df.dropna()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Transformasi: Menambahkan kolom keuntungan</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df_clean[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;profit&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> df_clean[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;pendapatan&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> df_clean[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;biaya&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Menyimpan hasil ke dalam format Parquet</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df_clean.to_parquet(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;output_penjualan.parquet&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">engine</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;pyarrow&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>Keuntungan membangun pipeline data dengan Dask:</p><ul><li><strong>Proses ETL lebih cepat dan efisien</strong> karena berjalan secara paralel.</li><li><strong>Dapat menangani banyak file sekaligus</strong>.</li><li><strong>Integrasi mudah dengan big data tools seperti Hadoop dan Spark</strong>.</li></ul><hr><h4 id="_2-menggunakan-dask-untuk-dashboard-analitik" tabindex="-1"><strong>2. Menggunakan Dask untuk Dashboard Analitik</strong> <a class="header-anchor" href="#_2-menggunakan-dask-untuk-dashboard-analitik" aria-label="Permalink to &quot;**2. Menggunakan Dask untuk Dashboard Analitik**&quot;">​</a></h4><p>Dask dapat digunakan untuk mengoptimalkan dashboard analitik yang membutuhkan pemrosesan data dalam jumlah besar.</p><h5 id="contoh-membuat-dashboard-sederhana-dengan-dask-dan-bokeh" tabindex="-1"><strong>Contoh: Membuat Dashboard Sederhana dengan Dask dan Bokeh</strong> <a class="header-anchor" href="#contoh-membuat-dashboard-sederhana-dengan-dask-dan-bokeh" aria-label="Permalink to &quot;**Contoh: Membuat Dashboard Sederhana dengan Dask dan Bokeh**&quot;">​</a></h5><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dask.dataframe </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dd</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> bokeh.plotting </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> figure, show</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> bokeh.io </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> output_file</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Membaca dataset besar</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dd.read_csv(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;sales_data.csv&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Menghitung total penjualan per bulan</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">monthly_sales </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> df.groupby(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;bulan&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;penjualan&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].sum().compute()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Membuat visualisasi dengan Bokeh</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">output_file(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;dashboard.html&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">p </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> figure(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">title</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Total Penjualan per Bulan&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">x_axis_label</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Bulan&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">y_axis_label</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Penjualan&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">p.line(monthly_sales.index, monthly_sales.values, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">line_width</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">show(p)</span></span></code></pre></div><p>Keuntungan menggunakan Dask untuk dashboard analitik:</p><ul><li><strong>Dapat menangani data dalam skala besar tanpa membebani memori.</strong></li><li><strong>Mempercepat waktu query pada data yang terus diperbarui.</strong></li><li><strong>Integrasi mudah dengan tools visualisasi seperti Bokeh dan Plotly.</strong></li><li><strong>Dask dapat diterapkan dalam analisis dataset besar dan pemrosesan data real-time.</strong></li><li><strong>Pipeline data dengan Dask mempercepat proses ETL dan analisis data skala besar.</strong></li><li><strong>Dask dapat digunakan untuk membangun dashboard analitik yang lebih efisien.</strong></li></ul>`,200)]))}const u=s(e,[["render",l]]);export{o as __pageData,u as default};
